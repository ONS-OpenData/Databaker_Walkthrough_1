{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Databaker - Intro, part 1\n",
    "\n",
    "Michael Adams, 04/05/2017\n",
    "\n",
    "A simple introduction to the databaker python library using a very basic hand crafted spreadsheet.\n",
    "\n",
    "This notebook is intended as an introduction to help explain what databaker is and what it can do rather than a complete showcase of capability (if there's interest I'll build more examples for that).\n",
    "\n",
    "Please note - I'm going to make heavy use of excel images to explain concepts in this walkthrough, but databaker is purely a python library so you will not use excel  at all in practice (or even need it installed).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## What is Databaker?\n",
    "\n",
    "Databaker is a python library for 'baking' irregularly formatted data (in the form of hand crafted spreadsheets) into strictly dimensioned machine readable datasets.\n",
    "\n",
    "The image below show some data (coloured in yellow) both in a spreadsheet and after the databaker process.\n",
    "\n",
    "---\n",
    "\n",
    "![alt text](images/both.png)\n",
    "\n",
    "---\n",
    "\n",
    "Take a moment and compare the two. You can see in the output (lower) picture how the relationship between the observations (the counts, values etc being measured) and their dimensions (which explain WHAT we're measuring) is obvious and clearly defined. This helps make it machine readable.\n",
    "\n",
    "In the upper picture (the hand crafted spreadsheet) these relationships are abstracted and represented visually, this sort of abstact is of limited use to a computerised data system.\n",
    "\n",
    "A key thing to understand at this point is that databaker recipes (i.e scripts) are repeat use. If you were to add additional groups to the above spreadsheet the recipe would still run and would accomodate the extra data seemlessly.\n",
    "\n",
    "In ONS context, if you add another month, quarter or year onto a spreadsheet no code modification would be required to databake it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# How does it work?\n",
    "\n",
    "There are four phases to the databaker process:\n",
    "    \n",
    "1.) Load a spreadsheet, and select the tabs you're interested in.\n",
    "\n",
    "2.) Select and group the cells.\n",
    "\n",
    "3.) Define the dimensions (the relationships between these groups of cells).\n",
    "\n",
    "4.) Output the result as a CSV.\n",
    "\n",
    "We'll take a look at each of these steps in turn and run a few code example. We'll use these to build up to the final recipe.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# First - the data\n",
    "\n",
    "We'll use the example spreadsheet show below. Its from a tab called \"Groups\" in a spreadsheet named \"databakerExamples.xlsx\".\n",
    "\n",
    "![alt text](images/source.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 1.) Load a spreadsheet, and select the tabs you're interested in.\n",
    "\n",
    "We need to import databaker and define the name of the input and output files we'll be using, then load the tabs we're interested in. \n",
    "\n",
    "NOTE - you can name the output file later if you like, but convention-wise its easier to do it at the start of a recipe, so the things most subject to change are in the same place.\n",
    "\n",
    "Providing you have the 'databakerExample.xlsx' file in the same directory as this file you can select and run the below code - you should get a few lines of output confirming filesize and the names ot tables loaded.\n",
    "\n",
    "Any line starting # is just a comment rather than code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading databakerExample.xlsx which has size 9932 bytes\n",
      "Table names: ['Groups']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# import the databaker framework - i.e tell the computer we're using databaker\n",
    "from databaker.framework import *\n",
    "\n",
    "# name the input and output file\n",
    "inputfile = 'databakerExample.xlsx'\n",
    "outputfile ='ExampleDatabakerOutput.csv'\n",
    "\n",
    "# load the tabs we want\n",
    "tabsWeWant = ['Groups']\n",
    "tabs = loadxlstabs(inputfile, tabsWeWant)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.) Select and group the cells.\n",
    "\n",
    "Databaker uses dot notation for selecting cells. Basically, you start with a selection of data and each additional .command modifies that selection somehow.\n",
    "\n",
    "In other words - each line is a sequence of commands executed one after the other.\n",
    "\n",
    "Here's a complete line:\n",
    "\n",
    "---\n",
    "\n",
    "![alt text](images/line1.png)\n",
    "\n",
    "We're now going to walk through this line of commands. We'll adress each .command in turn, highlighting which \"cells\" are selected as each command executes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 'tab' command\n",
    "\n",
    "This is the first command and the standard starting point - literally select all cells in the tab we are looking at.\n",
    "\n",
    "so:\n",
    "    \n",
    "![alt text](images/line2.png)\n",
    "\n",
    "gets us to:\n",
    "    \n",
    "![alt text](images/select1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## excel_ref('C5')\n",
    "\n",
    "means .... FROM THE CURRENT SELECTION ..... get us any cell with an 'excel reference' (letter/number) of 'C5'\n",
    "\n",
    "so:\n",
    "\n",
    "![alt text](images/line3.png)\n",
    "\n",
    "gets us to:\n",
    "    \n",
    "![alt text](images/select2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "\n",
    "## expand(DOWN)\n",
    "\n",
    "means .... FROM THE CURRENT SELECTION ..... expand downwards and select all cells, including current selection.\n",
    "\n",
    "NOTE - there is also a \".fill\" command that does the same thing but does NOT include the current selection.\n",
    "\n",
    "so:\n",
    "\n",
    "![alt text](images/line4.png)\n",
    "\n",
    "gets us to:\n",
    "    \n",
    "![alt text](images/select3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "## expand(RIGHT)\n",
    "\n",
    "means .... FROM THE CURRENT SELECTION ..... expand right selecting all cells, including current selection.\n",
    "\n",
    "NOTE - the \"FROM CURRENT SELECTION\" is important here. We select the cells to the right of ALL the cells currently selected.\n",
    "\n",
    "so:\n",
    "\n",
    "![alt text](images/line5.png)\n",
    "\n",
    "gets us to:\n",
    "    \n",
    "![alt text](images/select4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## is_not_blank()\n",
    "\n",
    "means .... FROM THE CURRENT SELECTION ..... only keep the cells, if each cell IS NOT BLANK.\n",
    "\n",
    "so:\n",
    "\n",
    "![alt text](images/line6.png)\n",
    "\n",
    "gets us to:\n",
    "    \n",
    "![alt text](images/select5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "\n",
    "# Selection - Putting it all together\n",
    "\n",
    "The following images use coloured cells and commands to highlight all four data selections we'll use in this databaker recipe.\n",
    "\n",
    "Fistly, here is the data we will be selecting:\n",
    "\n",
    "---\n",
    "\n",
    "![alt text](images/allColours.png)\n",
    "\n",
    "---\n",
    "\n",
    "Now, the commands you would use to select them.\n",
    "\n",
    "Please note: The words to the left of the = are just variable names I've chosen. You can use whatever you like but something relatively descriptive is always a good idea.\n",
    "\n",
    "\n",
    "![alt text](images/colCommands.png)\n",
    "\n",
    "Take a moment and run through the logic of these selections, making sure you understand how each command resulted in the selection of cells with the matching colour.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# 3.) Define the dimensions (the relationships between these groups of cells).\n",
    "\n",
    "\n",
    "At this stage we have all the data selected into groups of cells. We now need to define the relationships between these groups of cells.\n",
    "\n",
    "There is one Golden Rule that applies here:\n",
    "\n",
    "\n",
    "## you ALWAYS define relationships in terms of  each groups relationship to the observations.\n",
    "\n",
    " \n",
    " \n",
    "let's look at an example:\n",
    "\n",
    "Whats the relationship between \"assets\" and \"observations\"? - its that FOR ALL OBSERVATIONS the correct asset is directly above.\n",
    "\n",
    "---\n",
    "\n",
    "![alt text](images/relations.png)\n",
    "\n",
    "\n",
    "Using databaker syntax we write this as:\n",
    "\n",
    "\n",
    "\n",
    "## HDim(assets, \"Assets\", DIRECTLY, ABOVE)\n",
    "\n",
    "\n",
    "\n",
    "this command breaks down as follows:\n",
    "\n",
    "---\n",
    "\n",
    "![alt text](images/commandStuff.png)\n",
    "\n",
    "---\n",
    "\n",
    "The following is how you would define all the relationships in this example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Dont try and run the code in the cell please. It will not work as a stand alone.\n",
    "\n",
    "dimensions = [\n",
    "          HDim(assets, \"Assets\", DIRECTLY, ABOVE), \n",
    "          HDim(names, \"Name\", DIRECTLY, LEFT), \n",
    "          HDim(group, \"Group\", CLOSEST, ABOVE) \n",
    "             ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's looks at this in context of our coloured images.\n",
    "\n",
    "The key thing is to remember the mustard/yellow colour are the observations and all dimensions are defined relative to them.\n",
    "    \n",
    "---\n",
    "\n",
    "![alt text](images/allColours.png)\n",
    "\n",
    "---\n",
    "Take a moment and make sure you understand the logic behind how we've established the relationships.\n",
    "\n",
    "In the case of the \"CLOSEST, ABOVE\" commands used to define the groups dimension it works as follows:\n",
    "\n",
    "...for each observation, we want the cell in our groups selection that is the closest one above the observation cell in question. IMPORTANT - being on the same line is always counted as being CLOSEST, ABOVE.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 4.) Output the result as a CSV.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The final part of a databaker script is boiler plated - it never changes. \n",
    "\n",
    "As such we'll move straight to the final example recipe, you can see all the commands in context and hopefully they'll make a degree of sense now.\n",
    "\n",
    "Remember, the idea of this document is to give you a good overview on how the underlying logic and process works - nothing more. It's just a starting point.\n",
    "\n",
    "NOTE - I'll make heavy use of comments in this script (lines beginning #).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading databakerExample.xlsx which has size 10098 bytes\n",
      "Table names: ['Groups']\n",
      "writing 1 conversion segments into C:\\Databaker_Walkthrough_1\\ExampleDatabakerOutput.csv\n",
      "conversionwrite segment size 24 table 'Groups'; \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# import the databaker framework - i.e tell the computer we're using databaker\n",
    "from databaker.framework import *\n",
    "\n",
    "# name the input and output file\n",
    "inputfile = 'databakerExample.xlsx'\n",
    "outputfile ='ExampleDatabakerOutput.csv'\n",
    "\n",
    "# load the tabs we want\n",
    "tabsWeWant = ['Groups']\n",
    "tabs = loadxlstabs(inputfile, tabsWeWant)\n",
    "\n",
    "\n",
    "# define a list. this is mandatory - for later\n",
    "conversionsegments = []\n",
    "\n",
    "# for each of the selected tabs....do everything thats indented (in this case we only have 1 tab, but that isn't common so we'll stick with the typical approach)\n",
    "for tab in tabs:       \n",
    "\n",
    "    # define a selection of cells as the observations\n",
    "    observations = tab.excel_ref('C5').expand(DOWN).expand(RIGHT).is_not_blank()\n",
    "    \n",
    "    # define other selections of cells to be our dimensions\n",
    "    assets = tab.excel_ref('C3').expand(RIGHT).is_not_blank()\n",
    "    names = tab.excel_ref('B5').expand(DOWN).is_not_blank()\n",
    "    group = tab.excel_ref('A5').expand(DOWN).is_not_blank()\n",
    "\n",
    "    # define the relationships of the cells selected as dimensions (relative to the observations)\n",
    "    dimensions = [\n",
    "              HDim(assets, \"Assets\", DIRECTLY, ABOVE), \n",
    "              HDim(names, \"Name\", DIRECTLY, LEFT), \n",
    "              HDim(group, \"Group\", CLOSEST, ABOVE) \n",
    "                 ]\n",
    "    \n",
    "    # Now we process these relationship for this tab (this code never changes)\n",
    "    conversionsegment = ConversionSegment(tab, dimensions, observations) # < --- processing\n",
    "    conversionsegments.append(conversionsegment) # <-- adding result of processing this tab to our list\n",
    "    \n",
    "# print it all to csv (this code never changes)\n",
    "writetechnicalCSV(outputfile, conversionsegments)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Input and Output\n",
    "\n",
    "Here's the data before and after.\n",
    "\n",
    "---\n",
    "![alt text](images/source.png)\n",
    "---\n",
    "![alt text](images/output.png)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
